---
title: 'Privatization of AI research: Preprocessing'
author: "Daniel S. Hain (dsh@business.aau.dk)"
date: "Updated `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    code_folding: hide
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
    theme: flatly
---

```{r setup, include=FALSE}
# Knitr options
### Generic preamble
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
graphics.off()

Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation

### Load packages
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
```

# Papers & Conceps

## Read data

```{r}
data <- read_csv('../../input/works.csv') %>%
  mutate(id = id %>% as.character()) %>%
  select(-title, -issn,
         -concepts, -concepts_v1, -concepts_v3,
         -DI1, DI5, DI1nok, DI5nok, DeIn, Breadth, Depth) %>%
  rename(concepts = concepts_v2)
```


## Extract citations, novelty, OA

```{r}
indicators <- data %>% select(list_aid, year, list_aid, oa, cited_by_count, novelty_lee) %>%
  mutate(n_author = list_aid %>% str_count('\n'),
         list_aid = list_aid %>% str_split('\n')) %>% 
  unnest(list_aid) %>%
  rename(AID = list_aid) %>%
  group_by(AID, year) %>%
  summarise(
    author_mean = n_author %>% mean(na.rm = TRUE),
    paper_n = n(),
    citation_n = cited_by_count %>% sum(na.rm = TRUE),
    citation_mean = cited_by_count %>% mean(na.rm = TRUE),
    citation_max = cited_by_count %>% max(),
    oa_mean = oa %>% mean(),
    novelty_mean = novelty_lee %>% mean(na.rm = TRUE)
    #novelty_max = novelty_lee %>% max()
  ) %>%
  ungroup()
```

```{r}
indicators %>% write_rds('../../temp/author_indicators.rds')
```

```{r}
rm(indicators)
```


## Extract concepts

```{r}
concepts_paper <- data %>% select(id, year, list_aid, concepts) %>%
  mutate(concepts = concepts %>% str_split('\n')) %>% 
  unnest(concepts) %>%
  drop_na()
```

```{r}
rm(data)
```


```{r}
concepts_paper %>% count(concepts, sort = TRUE) %>% 
  mutate(pct = percent_rank(n))
```


### Concept reduction

```{r}
# ## Select by percentage
# pct_min = 0.5
# 
# concepts_main <- concepts %>% count(concepts, sort = TRUE) %>% 
#   filter(percent_rank(n) >= pct_min) %>%
#   drop_na()

## Select by number
n_concepts <- 100
n_start = 1

# Extract main concepts
concepts_main <- concepts_paper %>% 
  count(concepts, sort = TRUE) %>%
  slice(n_start:(n_start + n_concepts))

# # General concepts without informative value
concepts_drop <- c('algorithm')

concepts_main %<>%
  filter(!(concepts %in% concepts_drop ))
```

```{r}
## Update author dyn
# # Solution 1: Set to others
# concepts_paper %<>%
#   mutate(concepts = ifelse(concepts %in% (concepts_main %>% pull(concepts)), concepts, 'others')) 

# Solution 2
concepts_paper %<>%
  semi_join(concepts_main, by = 'concepts')
```


```{r}
concepts_paper %>% write_rds('../../temp/paper_concepts.rds')
```

```{r}
concepts_author <- concepts_paper
```

```{r}
rm(concepts_main,concepts_drop, n_start, n_concepts, concepts)
```


```{r}
 concepts_author %<>%
  mutate(list_aid = list_aid %>% str_split('\n')) %>% 
  unnest(list_aid) %>%
  rename(AID = list_aid) %>%
  drop_na()
```

```{r}
# Extract main concept per author
concepts_author_main <- concepts_author %>%
  count(AID, concepts) %>%
  group_by(AID) %>% 
  slice_max(order_by = n, n = 1, with_ties = FALSE) %>% 
  ungroup() %>%
  select(-n)

concepts_author_main %>% write_rds('../../temp/author_concepts_main.rds')
```

```{r}
concepts_author %<>%
  count(AID, year, concepts) 
```

```{r}
concepts_author %<>%
  group_by(AID, year) %>% 
  slice_max(order_by = n, n = 1, with_ties = FALSE) %>% 
  ungroup() %>%
  select(-n)
```

```{r}
concepts_author %<>%
  group_by(AID) %>%
    arrange(AID, year) %>%
    fill(concepts, .direction = "downup") %>%
  ungroup() 
```

```{r}
concepts_author %>%
  count(concepts, sort = TRUE)
```

```{r}
concepts_author %>% write_rds('../../temp/author_concepts.rds')
```


```{r}
# Delete all objects
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
```

# Main data (reearcher panel)

## Load data

```{r}
data <- read_csv('../../input/variables.csv') %>% 
  select(-seniority, -seniority_all, -paper_n, transited_t, -switcher, -concepts, -gender) %>%
  mutate(AID = AID %>% as.character()) 
```

## first preprocess

```{r}
data %<>% 
  mutate(aff_id = aff_id %>% str_remove('https://openalex.org/'))
```

## Static author

```{r}
data_static <- read_csv('../../input/author_static_detailed.csv') %>%
  mutate(AID = AID %>% as.character()) %>%
  filter(seniority >= 1960)
```

```{r}
data_static %>% count(type, sort = TRUE)
```

```{r}
# Filter by type
data_static %<>%
  filter(type %in% c('education', 'education_company')) %>% # Old: 'switcher'
  mutate(type = ifelse(type == 'education_company', 'switcher', type))
```


```{r}
author_range <- data %>%
  group_by(AID) %>%
  summarise(year_n = n(),
            year_min = year %>% min(na.rm = TRUE),
            year_max = year %>% max(na.rm = TRUE),
            year_transit = max(year * transition, na.rm = TRUE)
            ) %>%
  ungroup() %>%
  mutate(year_transit = ifelse(year_transit == 0, NA, year_transit),
         year_range = year_max - year_min + 1,
         pct_obs = year_range / year_n)
```

Now define the selection criteria for the sample

```{r}
author_range %<>%
  filter(
    year_min >= 1950,
    year_max >= 2010, # latest year observed
    year_n >= 3, # Number of years observed
    year_range >= 4, # Number of years observed
    pct_obs >= 0.5, # observed at least half of the time
    ) 
```

```{r}
# Merge with author static
data_static %<>%
  inner_join(author_range, by = 'AID')
```

```{r}
rm(author_range)
```

Now we already filter the panel data for our selection, so we dont have to do the lenghty preprocessing for all. 
Note: We do a semi and not an inner_join, since we want to join the static data into the panel only after the full range of years in the panel is constructed.

```{r}
# Filter data
data %<>% semi_join(data_static, by = 'AID')
```


## Join with other data

```{r}
# indicators
data %<>% left_join(read_rds('../../temp/author_indicators.rds') %>% select(AID, year, paper_n, author_mean, citation_n, oa_mean, novelty_mean), by = c('AID', 'year'))
```

```{r}
# concepts
data %<>% left_join(read_rds('../../temp/author_concepts.rds') %>% select(AID, year, concepts), by = c('AID', 'year'))
```

## Make complete panel

```{r}
data %<>%   
  group_by(AID) %>%
    complete(year = full_seq(min(year):max(year), 1)) %>%
    arrange(AID, year) %>%
    fill(aff_id, aff_type, DL, concepts, .direction = "downup") %>%
  ungroup() 
```

## Merge with author static

```{r}
data %<>% 
  inner_join(data_static %>% select(AID, type, seniority, year_transit, year_max, year_min), by = 'AID')
```

```{r}
data %<>%
  mutate(seniority = year - seniority + 1,
         transited_t = year - year_transit + 1) %>%
  mutate(transited_t = ifelse(transited_t < 1, NA, transited_t))
```


## Replace NAs

```{r}
data %>% naniar::gg_miss_var()
```


```{r}
# Replace again missing
data %<>%   
  group_by(AID) %>%
    arrange(AID, year) %>%
    fill(aff_id, aff_type, DL, concepts,
         citation_n, novelty_mean,
         .direction = "downup") %>%
  ungroup() 
```


  
```{r}
# Replace NAs
data %<>%
  replace_na(list(transition = 0, DL = 0,
                  deg_cen = 0, deg_cen_comp = 0,
                  paper_n = 0, author_mean = 0, citation_n = 0, oa_mean = 0, novelty_mean = 0,
                  concepts = 'unknown'))
```

```{r}
#in-between save
data %>% write_rds('../../temp/data_reg_temp.rds')
```

```{r}
#data <- read_rds('../../temp/data_reg_temp.rds')
```

## Field weighted indicators

```{r}
data %<>%
  group_by(concepts, year) %>%
  mutate(citation_fw = citation_n %>% percent_rank(),
         novelty_fw = novelty_mean %>% percent_rank()) %>%
  ungroup()
```


## Institutions

```{r}
data_institutions <- data %>%
  drop_na(aff_id) %>%
  group_by(aff_id, year) %>%
  summarise(author_n = n_distinct(AID),
            aff_paper_n = n(),
            aff_citation_fw = citation_fw %>% mean(),
            aff_novelty_fw = novelty_fw %>% mean()
            ) %>%
  ungroup() %>%
  mutate(across(everything(), ~replace(.x, is.nan(.x), 0)),
         across(everything(), ~replace(.x, is.na(.x), 0)))
```

```{r}
data_institutions %>% write_rds('../../temp/data_institutions.rds')
```

```{r}
data %<>% left_join(data_institutions %>% select(aff_id, year, aff_citation_fw, aff_novelty_fw), by = c('aff_id', 'year'))
```


```{r}
data  %>% naniar::gg_miss_var()
```

```{r}
# Replace NAs
data %<>%
  replace_na(list(aff_citation_fw = 0, aff_novelty_fw = 0))
```

```{r}
rm(data_institutions)
```

## Rolling mean

```{r}
data %<>% arrange(AID, year)
```

```{r}
data %<>%
  group_by(AID) %>%
  mutate(
    across(c(paper_n, 
             author_mean,
             citation_n, 
             oa_mean, 
             novelty_mean, 
             deg_cen, 
             deg_cen_comp, 
             novelty_fw, 
             citation_fw,
             aff_citation_fw,
             aff_novelty_fw), ~  zoo::rollmean(.x, 2, fill = c(0, NA, NA), align = "right"))) %>% 
  ungroup()

#  Alternative slider::slide_dbl(~mean(.x), .before = 2))
```




## some other small thingies

```{r}
# round long floats
data %<>%
  mutate(across(where(is_double), round, 3))
```

## Save

```{r}
data %>% write_rds('../../temp/data_reg.rds')
```

```{r}
sessionInfo()
```


